{"cells":[{"cell_type":"markdown","metadata":{"id":"TqYr7rnhRA5w"},"source":["---\n","\n","# <center> GFootball Stable-Baselines3 </center>\n","\n","---\n","<center><img src=\"https://raw.githubusercontent.com/DLR-RM/stable-baselines3/master/docs/_static/img/logo.png\" width=\"308\" height=\"268\" alt=\"Stable-Baselines3\"></center>\n","<center><small>Image from Stable-Baselines3 repository</small></center>\n","\n","---\n","This notebook uses the [Stable-Baselines3](https://github.com/DLR-RM/stable-baselines3) library to train a [PPO](https://openai.com/blog/openai-baselines-ppo/) reinforcement learning agent on [GFootball Academy](https://github.com/google-research/football/tree/master/gfootball/scenarios) scenarios, applying the architecture from the paper \"[Google Research Football: A Novel Reinforcement Learning Environment](https://arxiv.org/abs/1907.11180)\"."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"il5C4RB_RA52","outputId":"0f265404-4e90-4402-8c57-46de529288c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: cloudpickle==1.3.0 in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.5.1\n","  Downloading torch-1.5.1-cp37-cp37m-manylinux1_x86_64.whl (753.2 MB)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1) (1.21.6)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","Successfully installed torch-1.5.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gym==0.17.2\n","  Downloading gym-0.17.2.tar.gz (1.6 MB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2) (1.4.1)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2) (1.21.6)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2) (1.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.2) (0.16.0)\n","Building wheels for collected packages: gym\n","  Building wheel for gym (setup.py): started\n","  Building wheel for gym (setup.py): finished with status 'done'\n","  Created wheel for gym: filename=gym-0.17.2-py3-none-any.whl size=1650890 sha256=f16b116a60815429c5bf6c9608bbeb6b03aeb4f2b456e777ffebdd2b886d756d\n","  Stored in directory: /root/.cache/pip/wheels/18/e1/58/89a2aa24e6c2cc800204fc02010612afdf200926c4d6bfe315\n","Successfully built gym\n","Installing collected packages: gym\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.17.3\n","    Uninstalling gym-0.17.3:\n","      Successfully uninstalled gym-0.17.3\n","Successfully installed gym-0.17.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/football\n","Collecting pygame==1.9.6\n","  Downloading pygame-1.9.6-cp37-cp37m-manylinux1_x86_64.whl (11.4 MB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (4.1.2.30)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (1.4.1)\n","Requirement already satisfied: gym>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (0.17.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (1.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (0.37.1)\n","Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.8) (1.3.0)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.8) (1.21.6)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.8) (1.5.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.11.0->gfootball==2.8) (0.16.0)\n","Building wheels for collected packages: gfootball\n","  Building wheel for gfootball (setup.py): started\n","  Building wheel for gfootball (setup.py): finished with status 'done'\n","  Created wheel for gfootball: filename=gfootball-2.8-cp37-cp37m-linux_x86_64.whl size=38781744 sha256=46fdf4858d8987f1a1180721012d2e9780927bee98672760d3346f84000f50e5\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-5x1u76j8/wheels/bb/c2/92/82a23d0c207f5497a23f4316675eb1629e6be474bd2c3be61a\n","Successfully built gfootball\n","Installing collected packages: pygame, gfootball\n","Successfully installed gfootball-2.8 pygame-1.9.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/kaggle-environments\n","Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from kaggle-environments==1.9.10) (4.3.3)\n","Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from kaggle-environments==1.9.10) (1.1.4)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from kaggle-environments==1.9.10) (1.21.6)\n","Collecting requests>=2.25.1\n","  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.10) (7.1.2)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.10) (1.0.1)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.10) (1.1.0)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.10) (2.11.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.2->kaggle-environments==1.9.10) (2.0.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.10) (5.7.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.10) (4.2.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.10) (4.11.4)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.10) (0.18.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.10) (21.4.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.1->kaggle-environments==1.9.10) (3.8.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.10) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.10) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.10) (2022.5.18.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.10) (1.24.3)\n","Building wheels for collected packages: kaggle-environments\n","  Building wheel for kaggle-environments (setup.py): started\n","  Building wheel for kaggle-environments (setup.py): finished with status 'done'\n","  Created wheel for kaggle-environments: filename=kaggle_environments-1.9.10-py3-none-any.whl size=1820417 sha256=0151d04377a5182790ca86b6d53450179262644d5a8166757dadbaaf2f683ac9\n","  Stored in directory: /root/.cache/pip/wheels/67/f1/54/59176bd30840c0a045df67632e2e903095b3c02b64cb0a636c\n","Successfully built kaggle-environments\n","Installing collected packages: requests, kaggle-environments\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","Successfully installed kaggle-environments-1.9.10 requests-2.28.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/stable-baselines3\n","Collecting gym==0.21\n","  Downloading gym-0.21.0.tar.gz (1.5 MB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.5.1a8) (1.21.6)\n","Collecting torch>=1.11\n","  Downloading torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.5.1a8) (1.3.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.5.1a8) (1.3.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.5.1a8) (3.2.2)\n","Requirement already satisfied: importlib_metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21->stable-baselines3==1.5.1a8) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3==1.5.1a8) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable-baselines3==1.5.1a8) (4.2.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.5.1a8) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.5.1a8) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.5.1a8) (1.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.5.1a8) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3==1.5.1a8) (1.15.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3==1.5.1a8) (2022.1)\n","Building wheels for collected packages: stable-baselines3, gym\n","  Building wheel for stable-baselines3 (setup.py): started\n","  Building wheel for stable-baselines3 (setup.py): finished with status 'done'\n","  Created wheel for stable-baselines3: filename=stable_baselines3-1.5.1a8-py3-none-any.whl size=165288 sha256=244afa39104081aa2423f4dc0a49e9064685915d358112a702cbe650c3fd4307\n","  Stored in directory: /root/.cache/pip/wheels/4f/01/f8/0ee43258c77e3fc8cb1e6c0e254015c64284b42569880166fa\n","  Building wheel for gym (setup.py): started\n","  Building wheel for gym (setup.py): finished with status 'done'\n","  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616826 sha256=55bc16b67cb3be596c036dfaabfff2f39695c0608ebd68d85bfa1fb513a71bff\n","  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n","Successfully built stable-baselines3 gym\n","Installing collected packages: torch, gym, stable-baselines3\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.5.1\n","    Uninstalling torch-1.5.1:\n","      Successfully uninstalled torch-1.5.1\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.17.2\n","    Uninstalling gym-0.17.2:\n","      Successfully uninstalled gym-0.17.2\n","Successfully installed gym-0.21.0 stable-baselines3-1.5.1a8 torch-1.11.0\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.5.1 which is incompatible.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.5.1 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.5.1 which is incompatible.\n","Cloning into 'football'...\n","  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n","Cloning into 'kaggle-environments'...\n","  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.5.1 which is incompatible.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.5.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","Cloning into 'stable-baselines3'...\n","  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n"]}],"source":["%%bash\n","# dependencies\n","apt-get -y update > /dev/null\n","apt-get -y install libsdl2-gfx-dev libsdl2-ttf-dev > /dev/null\n","\n","# cloudpickle, pytorch, gym\n","pip3 install \"cloudpickle==1.3.0\"\n","pip3 install \"torch==1.5.1\"\n","pip3 install \"gym==0.17.2\"\n","\n","# gfootball\n","GRF_VER=v2.8\n","GRF_PATH=football/third_party/gfootball_engine/lib\n","GRF_URL=https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_${GRF_VER}.so\n","git clone -b ${GRF_VER} https://github.com/google-research/football.git\n","mkdir -p ${GRF_PATH}\n","wget -q ${GRF_URL} -O ${GRF_PATH}/prebuilt_gameplayfootball.so\n","cd football && GFOOTBALL_USE_PREBUILT_SO=1 pip3 install . && cd ..\n","\n","# kaggle-environments\n","git clone https://github.com/Kaggle/kaggle-environments.git\n","cd kaggle-environments && pip3 install . && cd ..\n","\n","# stable-baselines3\n","git clone https://github.com/DLR-RM/stable-baselines3.git\n","cd stable-baselines3 && pip3 install . && cd ..\n","\n","# housekeeping\n","# rm -rf football kaggle-environments stable-baselines3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTZCUI7rRA54"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","code_path = '/content/drive/My Drive/RL/Final_project/Colab'\n","sys.path.insert(0,code_path)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZMbp-m4rRA55"},"outputs":[],"source":["import os\n","import base64\n","import pickle\n","import zlib\n","import gym\n","import numpy as np\n","import pandas as pd\n","import torch as th\n","from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n","from torch import nn, tensor\n","from collections import deque\n","from gym.spaces import Box, Discrete\n","from kaggle_environments import make\n","from kaggle_environments.envs.football.helpers import *\n","from gfootball.env import create_environment, observation_preprocessing\n","from gfootball.env.wrappers import Simple115StateWrapper\n","from stable_baselines3 import PPO\n","from stable_baselines3.ppo import CnnPolicy\n","from stable_baselines3.common import results_plotter\n","from stable_baselines3.common.callbacks import BaseCallback\n","from stable_baselines3.common.env_checker import check_env\n","from stable_baselines3.common.monitor import Monitor\n","from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n","from stable_baselines3.common.vec_env.dummy_vec_env import DummyVecEnv\n","from stable_baselines3.common.vec_env.subproc_vec_env import SubprocVecEnv\n","from stable_baselines3.common.env_util import make_vec_env\n","\n","from IPython.display import HTML\n","from visualizer import visualize\n","\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","\n","opponentpath=code_path + \"/opponent/\"\n","for filename in os.listdir(opponentpath):\n","  fullpath = opponentpath+filename\n","  !cp -r $fullpath /content/football/gfootball/scenarios\n","\n","!cd football && GFOOTBALL_USE_PREBUILT_SO=1 pip3 install . && cd .."]},{"cell_type":"markdown","metadata":{"id":"kAdUm79jRA57"},"source":["---\n","# Football Gym\n","> [Stable-Baselines3: Custom Environments](https://stable-baselines3.readthedocs.io/en/master/guide/custom_env.html)<br/>\n","> [SEED RL Agent](https://www.kaggle.com/piotrstanczyk/gfootball-train-seed-rl-agent): stacked observations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SaLNRqT3bAdg"},"outputs":[],"source":["# prev_obs is the obs before the action is taken, obs is the next obs as a result of the action.\n","def reward_modifier(rew, action, prev_obs, obs):\n","  \n","  ball_x, ball_y, ball_z = obs['ball']\n","  MIDDLE_X, PENALTY_X, END_X = 0.2, 0.64, 1.0\n","  PENALTY_Y, END_Y = 0.27, 0.42\n","\n","  # Ball position\n","  ball_position_r = 0.0\n","  if   (-END_X <= ball_x    and ball_x < -PENALTY_X)and (-PENALTY_Y < ball_y and ball_y < PENALTY_Y):\n","      ball_position_r = -2.0\n","  elif (-END_X <= ball_x    and ball_x < -MIDDLE_X) and (-END_Y < ball_y     and ball_y < END_Y):\n","      ball_position_r = -1.0\n","  elif (-MIDDLE_X <= ball_x and ball_x <= MIDDLE_X) and (-END_Y < ball_y     and ball_y < END_Y):\n","      ball_position_r = 0.0\n","  elif (PENALTY_X < ball_x  and ball_x <=END_X)     and (-PENALTY_Y < ball_y and ball_y < PENALTY_Y):\n","      ball_position_r = 2.0\n","  elif (MIDDLE_X < ball_x   and ball_x <=END_X)     and (-END_Y < ball_y     and ball_y < END_Y):\n","      ball_position_r = 1.0\n","  else:\n","      ball_position_r = 0.0\n","\n","  # Yellow card \n","  left_yellow = np.sum(obs[\"left_team_yellow_card\"]) -  np.sum(prev_obs[\"left_team_yellow_card\"])\n","  right_yellow = np.sum(obs[\"right_team_yellow_card\"]) -  np.sum(prev_obs[\"right_team_yellow_card\"])\n","  yellow_r = right_yellow - left_yellow\n","  \n","  # Score \n","  win_reward = 0.0\n","  if obs['steps_left'] == 0:\n","      [my_score, opponent_score] = obs['score']\n","      if my_score > opponent_score:\n","          win_reward = 1.0\n","\n"," \n","\n","  return 5.0*rew + 5.0*win_reward + 0.003*ball_position_r + yellow_r \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExI9IOXyRA58"},"outputs":[],"source":["from stable_baselines3.common.env_checker import _check_obs\n","\n","class FootballGym(gym.Env):\n","    spec = None\n","    metadata = None\n","    \n","    def __init__(self, config=None):\n","        super(FootballGym, self).__init__()\n","        env_name = \"academy_empty_goal_close\"\n","        rewards = \"scoring,checkpoints\"\n","        self.reward_mod = True\n","        if config is not None:\n","            env_name = config.get(\"env_name\", env_name)\n","            rewards = config.get(\"rewards\", rewards)\n","            self.reward_mod = config.get(\"reward_mod\", self.reward_mod)\n","        self.env = create_environment(\n","            env_name=env_name,\n","            stacked=False,\n","            representation=\"raw\",\n","            rewards = rewards,\n","            write_goal_dumps=False,\n","            write_full_episode_dumps=False,\n","            render=False,\n","            write_video=False,\n","            dump_frequency=1,\n","            logdir=\".\",\n","            extra_players=None,\n","            number_of_left_players_agent_controls=1,\n","            number_of_right_players_agent_controls=0)  \n","        self.action_space = Discrete(19)\n","                \n","        # action_shape = np.shape(self.env.action_space)\n","        # shape = (action_shape[0] if len(action_shape) else 1, 115)\n","        self.observation_space = gym.spaces.Box(\n","        low=-np.inf, high=np.inf, shape=(115, ), dtype=np.float32)\n","        self.prev_obs = self.observation_space.sample()[0]\n","\n","  # elif representation == 'simple115':\n","  #   env = wrappers.Simple115StateWrapper(env)\n","  # elif representation == 'simple115v2':\n","  #   env = wrappers.Simple115StateWrapper(env, True)\n","  # elif representation == 'extracted':\n","  #   env = wrappers.SMMWrapper(env, channel_dimensions)\n","  # elif representation == 'raw':\n","\n","\n","    def transform_obs(self, raw_obs):\n","        obs = Simple115StateWrapper.convert_observation(raw_obs, True)\n","        return obs[0]\n","\n","    def reset(self):\n","    \n","        obs = self.env.reset()\n","        self.prev_obs = obs[0]\n","        obs = self.transform_obs(obs)      \n","        return obs\n","    \n","    def step(self, action):\n","        obs, reward, done, info = self.env.step([action])\n","        final_reward = reward\n","        if self.reward_mod == True:\n","          final_reward = reward_modifier(reward, action, self.prev_obs, obs[0])\n","        self.prev_obs = obs[0]\n","        obs = self.transform_obs(obs)\n","        return obs, float(final_reward), done, info\n","    \n","check_env(env=FootballGym(), warn=True)"]},{"cell_type":"markdown","metadata":{"id":"9NYFra0aRA5-"},"source":["---\n","# Football CNN\n","> [Stable-Baselines3: Custom Policy Network](https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html)<br/>\n","> [Google Research Football: A Novel Reinforcement Learning Environment](https://arxiv.org/abs/1907.11180)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v9RXkx-HRA5_"},"outputs":[],"source":["def conv3x3(in_channels, out_channels, stride=1):\n","    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=True)\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","        self.relu = nn.ReLU()\n","        self.conv1 = conv3x3(in_channels, out_channels, stride)\n","        self.conv2 = conv3x3(out_channels, out_channels, stride)\n","        \n","    def forward(self, x):\n","        residual = x\n","        out = self.relu(x)\n","        out = self.conv1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out += residual\n","        return out\n","    \n","class FootballCNN(BaseFeaturesExtractor):\n","    def __init__(self, observation_space, features_dim=256):\n","        super().__init__(observation_space, features_dim)\n","        in_channels = observation_space.shape[0]  # channels x height x width\n","        self.cnn = nn.Sequential(\n","            conv3x3(in_channels=in_channels, out_channels=32),\n","            nn.MaxPool2d(kernel_size=3, stride=2, dilation=1, ceil_mode=False),\n","            ResidualBlock(in_channels=32, out_channels=32),\n","            ResidualBlock(in_channels=32, out_channels=32),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","        )\n","        self.linear = nn.Sequential(\n","          nn.Linear(in_features=52640, out_features=features_dim, bias=True),\n","          nn.ReLU(),\n","        )\n","\n","    def forward(self, obs):\n","        return self.linear(self.cnn(obs))"]},{"cell_type":"markdown","metadata":{"id":"yjVdYwqeRA6C"},"source":["---\n","# MODIFY HERE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tz2FcncMRA6G"},"outputs":[],"source":["filepath = \"/content/drive/My Drive/RL/Final_project/trained_agent\"\n","experiment = \"gfootball_simple115\"\n","log_dir = f\"{filepath}/{experiment}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hgaVqX1pM0hO"},"outputs":[],"source":["training_scenarios = {0: \"11_vs_11_easy_stochastic\",\n","             1: \"11_vs_11_easy_stochastic_2\",\n","             2: \"11_vs_11_easy_stochastic_4\",\n","             3: \"11_vs_11_stochastic\",\n","             4: \"11_vs_11_hard_stochastic_8\",\n","             5: \"11_vs_11_hard_stochastic\",\n","             6: \"11_vs_11_kaggle\",\n","             7: \"lazy_no_early_finish\",\n","             8: \"academy_empty_goal_close\",\n","             9: \"academy_empty_goal\",\n","             10: \"academy_run_to_score\",\n","             11: \"academy_run_to_score_with_keeper\",\n","             12: \"academy_pass_and_shoot_with_keeper\",\n","             13: \"academy_run_pass_and_shoot_with_keeper\",\n","             14: \"academy_3_vs_1_with_keeper\",\n","             15: \"academy_corner\",\n","             16: \"academy_counterattack_easy\",\n","             17: \"academy_counterattack_hard\",\n","             18: \"academy_single_goal_versus_lazy\",\n","             19: \"11_vs_11_kaggle\"\n","}\n","training_scenario_name = training_scenarios[0]"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"QKF7xmE5RA6H","executionInfo":{"status":"ok","timestamp":1655537228272,"user_tz":-540,"elapsed":912,"user":{"displayName":"최이솔","userId":"10373119228991456577"}}},"outputs":[],"source":["model = PPO.load(\"/content/drive/My Drive/fast_model\")\n","model.save(\"ppo_gfootball\")\n","total_timesteps = 1000\n","n_envs=8"]},{"cell_type":"markdown","metadata":{"id":"ID0SLwQRRA6I"},"source":["---\n","# Training\n","> [Stable-Baselines3: Examples](https://stable-baselines3.readthedocs.io/en/master/guide/examples.html)<br/>\n","> [Stable-Baselines3: Callbacks](https://stable-baselines3.readthedocs.io/en/master/guide/callbacks.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P8KC8rR33wry"},"outputs":[],"source":["%load_ext tensorboard\n","%tensorboard --logdir \"{filepath}/tensorboard\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"axme3pIlRA6K"},"outputs":[],"source":["plt.style.use(['seaborn-whitegrid'])\n","results_plotter.plot_results([log_dir], total_timesteps, results_plotter.X_TIMESTEPS, \"GFootball Timesteps\")\n","results_plotter.plot_results([log_dir], total_timesteps, results_plotter.X_EPISODES, \"GFootball Episodes\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-iXeWZKRA6L"},"outputs":[],"source":["plt.style.use(['seaborn-whitegrid'])\n","log_files = [os.path.join(log_dir, f\"{i}.monitor.csv\") for i in range(n_envs)]\n","\n","nrows = np.ceil(n_envs/2)\n","fig = plt.figure(figsize=(8, 2 * nrows))\n","for i, log_file in enumerate(log_files):\n","    if os.path.isfile(log_file):\n","        df = pd.read_csv(log_file, skiprows=1)\n","        plt.subplot(nrows, 2, i+1, label=log_file)\n","        df['r'].rolling(window=100).mean().plot(title=f\"Rewards: Env {i}\")\n","        plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOEwpWFuRA6L"},"outputs":[],"source":["%%writefile submission.py\n","import base64\n","import pickle\n","import zlib\n","import numpy as np\n","import torch as th\n","from torch import nn, tensor\n","from collections import deque\n","from gfootball.env import observation_preprocessing\n","\n","state_dict = _STATE_DICT_\n","\n","state_dict = pickle.loads(zlib.decompress(base64.b64decode(state_dict)))\n","\n","def conv3x3(in_channels, out_channels, stride=1):\n","    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=True)\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","        self.relu = nn.ReLU()\n","        self.conv1 = conv3x3(in_channels, out_channels, stride)\n","        self.conv2 = conv3x3(out_channels, out_channels, stride)\n","        \n","    def forward(self, x):\n","        residual = x\n","        out = self.relu(x)\n","        out = self.conv1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out += residual\n","        return out\n","    \n","class PyTorchCnnPolicy(nn.Module):\n","    global state_dict\n","    def __init__(self):\n","        super().__init__()\n","        self.cnn = nn.Sequential(\n","            conv3x3(in_channels=16, out_channels=32),\n","            nn.MaxPool2d(kernel_size=3, stride=2, dilation=1, ceil_mode=False),\n","            ResidualBlock(in_channels=32, out_channels=32),\n","            ResidualBlock(in_channels=32, out_channels=32),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","        )\n","        self.linear = nn.Sequential(\n","          nn.Linear(in_features=52640, out_features=256, bias=True),\n","          nn.ReLU(),\n","        )\n","        self.policy_net = nn.Sequential(\n","          nn.Linear(in_features=256, out_features=64, bias=True),\n","          nn.Tanh(),\n","          nn.Linear(in_features=64, out_features=64, bias=True),\n","          nn.Tanh(),\n","        )\n","        self.action_net = nn.Sequential(\n","          nn.Linear(in_features=64, out_features=19, bias=True),\n","          nn.ReLU(),\n","        )\n","        self.out_activ = nn.Softmax(dim=1)\n","        self.load_state_dict(state_dict)\n","\n","    def forward(self, x):\n","        x = tensor(x).float() / 255.0  # normalize\n","        x = x.permute(0, 3, 1, 2).contiguous()  # 1 x channels x height x width\n","        x = self.cnn(x)\n","        x = self.linear(x)\n","        x = self.policy_net(x)\n","        x = self.action_net(x)\n","        x = self.out_activ(x)\n","        return int(x.argmax())\n","    \n","obs_stack = deque([], maxlen=4)\n","def transform_obs(raw_obs):\n","    global obs_stack\n","    obs = raw_obs['players_raw'][0]\n","    obs = observation_preprocessing.generate_smm([obs])\n","    if not obs_stack:\n","        obs_stack.extend([obs] * 4)\n","    else:\n","        obs_stack.append(obs)\n","    obs = np.concatenate(list(obs_stack), axis=-1)\n","    return obs\n","\n","policy = PyTorchCnnPolicy()\n","policy = policy.float().to('cpu').eval()\n","def agent(raw_obs):\n","    obs = transform_obs(raw_obs)\n","    action = policy(obs)\n","    return [action]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wYsp3tZuSoRt"},"outputs":[],"source":["model = PPO.load(\"/content/drive/My Drive/AIcapstone/RL/Final_project/trained_agent/gfootball_simple115/10160000/best_model.zip\")\n","_state_dict = model.policy.to('cpu').state_dict()\n","state_dict = {\n","    \"cnn.0.weight\":_state_dict['features_extractor.cnn.0.weight'], \n","    \"cnn.0.bias\":_state_dict['features_extractor.cnn.0.bias'], \n","    \"cnn.2.conv1.weight\":_state_dict['features_extractor.cnn.2.conv1.weight'], \n","    \"cnn.2.conv1.bias\":_state_dict['features_extractor.cnn.2.conv1.bias'],\n","    \"cnn.2.conv2.weight\":_state_dict['features_extractor.cnn.2.conv2.weight'], \n","    \"cnn.2.conv2.bias\":_state_dict['features_extractor.cnn.2.conv2.bias'], \n","    \"cnn.3.conv1.weight\":_state_dict['features_extractor.cnn.3.conv1.weight'], \n","    \"cnn.3.conv1.bias\":_state_dict['features_extractor.cnn.3.conv1.bias'], \n","    \"cnn.3.conv2.weight\":_state_dict['features_extractor.cnn.3.conv2.weight'], \n","    \"cnn.3.conv2.bias\":_state_dict['features_extractor.cnn.3.conv2.bias'], \n","    \"linear.0.weight\":_state_dict['features_extractor.linear.0.weight'], \n","    \"linear.0.bias\":_state_dict['features_extractor.linear.0.bias'], \n","    \"policy_net.0.weight\":_state_dict['mlp_extractor.policy_net.0.weight'],\n","    \"policy_net.0.bias\":_state_dict['mlp_extractor.policy_net.0.bias'],\n","    \"policy_net.2.weight\":_state_dict['mlp_extractor.policy_net.2.weight'],\n","    \"policy_net.2.bias\":_state_dict['mlp_extractor.policy_net.2.bias'],\n","    \"action_net.0.weight\":_state_dict['action_net.weight'],\n","    \"action_net.0.bias\":_state_dict['action_net.bias'],\n","}\n","state_dict = base64.b64encode(zlib.compress(pickle.dumps(state_dict)))\n","with open('submission.py', 'r') as file:\n","    src = file.read()\n","src = src.replace(\"_STATE_DICT_\", f\"{state_dict}\")\n","with open('submission.py', 'w') as file:\n","    file.write(src)"]},{"cell_type":"markdown","metadata":{"id":"xRRUsElDRA6O"},"source":["---\n","# Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZWSnQFj8ojV"},"outputs":[],"source":["from stable_baselines3.common.monitor import Monitor as TrainMonitor\n","import glob\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import io\n","import base64\n","from IPython.display import HTML, clear_output\n","from IPython import display as ipythondisplay\n","from gym.wrappers import Monitor as eval_Monitor\n","\n","def show_video(episode, rnd):\n","  mp4list = glob.glob(f'video_{episode}_{rnd}/*.mp4')\n","  if len(mp4list) > 0:\n","    mp4 = mp4list[0]\n","    os.system(f\"ffmpeg -i {mp4} -vcodec libx264 video_{episode}_{rnd}/compressed.mp4\")\n","    video = io.open(f'video_{episode}_{rnd}/compressed.mp4', 'r+b').read()\n","    encoded = base64.b64encode(video)\n","    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n","                loop controls style=\"height: 200px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","  else: \n","    print(\"Could not find video\")\n","\n","def wrap_env(env, episode, rnd):\n","    env = eval_Monitor(env, f'./video_{episode}_{rnd}', force=True)\n","    return env"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j8xZuU1mOyE7"},"outputs":[],"source":["config={\"env_name\":training_scenario_name, \"rewards\":\"scoring\", \"reward_mod\": False}\n","test_env = FootballGym(config)\n","obs = test_env.reset()\n","done = False\n","total_reward=0\n","\n","\n","while not done:\n","    action, state = model.predict(obs, deterministic=True)\n","    obs, reward, done, info = test_env.step(action)\n","    total_reward+=reward\n","\n","print(total_reward)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270975,"status":"ok","timestamp":1655537504179,"user":{"displayName":"최이솔","userId":"10373119228991456577"},"user_tz":-540},"id":"wiZHX1u0g_-r","outputId":"51e94d0d-389e-44c2-a7bb-78d9c8774cb4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n","  UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -19.0], [3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001, 3001])\n"]}],"source":["from stable_baselines3.common.evaluation import evaluate_policy\n","\n","config={\"env_name\":training_scenario_name, \"rewards\":\"scoring\", \"reward_mod\": False}\n","test_env = FootballGym(config)\n","\n","print(evaluate_policy(model, test_env, n_eval_episodes=10,return_episode_rewards=True))\n","# print(mean_reward, std_reward)\n","\n","\n","# obs = test_env.reset()\n","# done = False\n","# total_reward=0\n","# while not done:\n","#     action, state = model.predict(obs, deterministic=True)\n","#     obs, reward, done, info = test_env.step(action)\n","#     total_reward+=reward\n","\n","#     # print(f\"{Action(action).name.ljust(16,' ')}\\t{round(reward,2)}\\t{info}\")\n","# print(total_reward)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKWGB6sERA6Q"},"outputs":[],"source":["kaggle_env = make(\"football\", debug = False,\n","                  configuration={\"scenario_name\": training_scenario_name, \n","                                 \"running_in_notebook\": True,\n","                                 \"save_video\": True})\n","output = kaggle_env.run([\"submission.py\", \"run_right\"])\n","print(output)\n","scores = output[-1][0][\"observation\"][\"players_raw\"][0][\"score\"]\n","print(\"Scores  {0} : {1}\".format(*scores))\n","print(\"Rewards {0} : {1}\".format(output[-1][0][\"reward\"], output[-1][1][\"reward\"]))\n","\n","viz = visualize(output)\n","\n","HTML(viz.to_html5_video())\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RFYdzKfbRA6Q"},"source":["> Modified [Human Readable Visualization](https://www.kaggle.com/jaronmichal/human-readable-visualization)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MnjbCkgmRA6Q"},"outputs":[],"source":["env = make(\"football\", configuration={\"save_video\": True, \"scenario_name\": training_scenario_name, \"running_in_notebook\": True}, debug=True)\n","agent = \"submission.py\"\n","output = env.run([agent, \"run_right\"])[-1]\n","print('Left player: action = %s, reward = %s, status = %s, info = %s' % (output[0][\"action\"], output[0]['reward'], output[0]['status'], output[0]['info']))\n","print('Right player: action = %s, reward = %s, status = %s, info = %s' % (output[1][\"action\"], output[1]['reward'], output[1]['status'], output[1]['info']))\n","env.render(mode=\"human\", width=800, height=600)"]},{"cell_type":"markdown","metadata":{"id":"00yZSEclLw-_"},"source":["3D VIDEO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HSBqtWV0LypS"},"outputs":[],"source":["import cv2\n","class FootballGym_Video(gym.Env):\n","    spec = None\n","    metadata = None\n","    \n","    def __init__(self,scenario_name=None, path=None):\n","        super(FootballGym_Video, self).__init__()\n","        env_name = scenario_name\n","        rewards = \"scoring\"\n","        self.env = create_environment(\n","            env_name=env_name,\n","            stacked=False,\n","            representation=\"raw\",\n","            rewards = rewards,\n","            write_goal_dumps=False,\n","            write_full_episode_dumps=True,\n","            render=True,\n","            write_video=True,\n","            dump_frequency=1,\n","            logdir=path,\n","            extra_players=None,\n","            number_of_left_players_agent_controls=1,\n","            number_of_right_players_agent_controls=0)  \n","        self.action_space = Discrete(19)\n","        self.observation_space = gym.spaces.Box(\n","        low=-np.inf, high=np.inf, shape=(115, ), dtype=np.float32)\n","        self.prev_obs = self.observation_space.sample()[0]\n","\n","    def transform_obs(self, raw_obs):\n","        obs = Simple115StateWrapper.convert_observation(raw_obs, True)\n","        return obs[0]\n","\n","    def reset(self):\n","    \n","        obs = self.env.reset()\n","        self.prev_obs = obs[0]\n","        obs = self.transform_obs(obs)\n","        return obs\n","    \n","    def step(self, action):\n","        obs, reward, done, info = self.env.step([action])\n","        final_reward = reward\n","        self.prev_obs = obs[0]\n","        obs = self.transform_obs(obs)\n","        return obs, float(final_reward), done, info\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":160311,"status":"ok","timestamp":1655089277766,"user":{"displayName":"Alvin Jinsung Choi","userId":"13853962861999871335"},"user_tz":-540},"id":"Tke_5QSqMesD","outputId":"0be0aeab-15c5-4366-91b9-c7bb63d4e02c"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.0\n","video was saved in/content/drive/My Drive/\n"]}],"source":["# model = PPO.load(\"ppo_gfootball\")\n","video_dump_path = \"/content/drive/My Drive/\"\n","\n","# test_env.close()\n","# test_env.env.close()\n","test_env = FootballGym_Video(training_scenario_name,video_dump_path)\n","obs = test_env.reset()\n","done = False\n","total_reward=0\n","\n","\n","while not done:\n","    action, state = model.predict(obs, deterministic=True)\n","    obs, reward, done, info = test_env.step(action)\n","    total_reward+=reward\n","\n","\n","test_env.env.close()\n","\n","print(total_reward)\n","print(\"video was saved in\"+video_dump_path)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"gfootball-stable-baselines3_evaluate_115.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}